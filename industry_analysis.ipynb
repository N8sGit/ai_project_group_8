{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7209e4-3605-478b-99da-26069ad65d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required libraries\n",
    "!pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c9ded7-b4be-4175-933f-3df2b445cfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "# NOTE: We might not use all of these. I just improrted everything I can think of for now. We'll delete the ones we don't need later\n",
    "import requests\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import json\n",
    "import path\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681e429e-361f-401b-880d-1a9b83533c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data into the notebook\n",
    "linkedin_postings_df = pd.read_csv('./data_sets/postings.csv').dropna()\n",
    "machine_learning_jobs_df = pd.read_json('./data_sets/job_data.json', lines=True)\n",
    "\n",
    "# Normalize, clean, massage, and combine data for ease of processing\n",
    "\n",
    "# Cast all job skills to lower case strings to standardize string matching later\n",
    "linkedin_postings_df['job_skills'] = linkedin_postings_df['job_skills'].apply(lambda item: item.lower().split(', '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dad630-f2c6-4262-92c4-a63ffc8c0cdb",
   "metadata": {},
   "source": [
    "***Introduction*** \n",
    "The goal of this exploratory data analysis is to characterize and investigate the growth of machine learning as a job skill. We are interested in looking at this topic along a number angles. TBC....\n",
    "Our dataset includes 9367 job postings takend from linkedin for the 2023 calendar year. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d17b49a-4c47-4758-817c-2084eed6651d",
   "metadata": {},
   "source": [
    "QUESTION Geography "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec3de0c-bc6d-4497-9c21-6ee5549343e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Question 1 analysis and visualizations here. Insert new cells if necessary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00c0439-518c-40c7-bd8f-87660d6adb82",
   "metadata": {},
   "source": [
    "Q1 Summary \\[INSERT SUMMARY HERE] ... write a little about what the findings above seem to indicate about question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2796093-8afa-492d-a021-b5e54cb2d645",
   "metadata": {},
   "source": [
    "**Section 2: Relative Comparisons of Tech Workers with/without Machine Learning **\n",
    "Another dimension by which to look at the growth of machine learning is to compare software developers *with* ML experience to those *without* machine learning experience. Layoffs among general tech workers have been pronounced in recent months [Link](https://layoffs.fyi/) yet demand for Machine Learning engineers has reportedly increased 42% on Hired's platform [Link](https://hired.com/resources/articles/trends-software-engineer-specializations/) . This demonstrates that as a specialization, ML ought to be treated separately from other tech skills.\n",
    "\n",
    "***Basic metrics***\n",
    "As a firsts step, we compare the relative proportion of machine learning related job listings to those lacking that term. We achieve this by doing a string match through the data set using a common list of ML related terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18886b70-e0cc-4ecd-a7fd-2ac608dd22fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all job listings with an AI related keyword  listed as a skill requirement \n",
    "terms_to_match = ['machine learning', 'artificial intelligence', 'pytorch', 'langchain', 'ai', 'tensorflow', 'deep learning', 'neural network', \n",
    "               'natural language processing', 'nlp', 'computer vision', 'large language models', 'chatbot', 'ai chatbot', 'llm', 'llms', 'generative ai', 'generative models', 'genai', 'bert', 'spacy', 'nltk', 'keras', 'gpt', 'chatgpt', 'prompt development', 'prompt engineering']\n",
    "\n",
    "linkedin_postings_df['job_skills'] = linkedin_postings_df['job_skills']\n",
    "\n",
    "linkedin_postings_df['has_ai'] = linkedin_postings_df['job_skills'].apply(\n",
    "    lambda skills: any(term in skills for term in terms_to_match)\n",
    ")\n",
    "#Separate the groupings into two new dataframes\n",
    "ai_roles = linkedin_postings_df.loc[linkedin_postings_df['has_ai'] == True]\n",
    "# Job listings without AI keywords will be classified as \"general\" roles\n",
    "general_roles = linkedin_postings_df.loc[linkedin_postings_df['has_ai'] == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811d415a-539d-4be0-ba3b-40997e599697",
   "metadata": {},
   "source": [
    "Relative proportion of ML jobs to non-ML tech jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c38774-13ec-442f-824d-21caeb9ac016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw counts of ML to non-ML\n",
    "display(linkedin_postings_df['has_ai'].value_counts())\n",
    "# Proportion of ML to non-ML\n",
    "display(linkedin_postings_df['has_ai'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fac1df-30ed-4197-8a1f-11e235cede69",
   "metadata": {},
   "source": [
    "Given that x of the y job listings contain an AI related keyword, approximately z% of all listings are AI-related to some degree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bde191-1386-48d8-bc5e-f59699069c8b",
   "metadata": {},
   "source": [
    "Another dimension we want to investigate is the relative proportion of job levels, or experience requirements. Considering that AI is a newer skill set, we predict a greater proportion of entry level positions compared to generic tech roles based on skills that have been around longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9c1fec-6706-4c96-b23e-b69dc779cfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ai_roles['job level'].value_counts(normalize=True))\n",
    "print(general_roles['job level'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92137d1-0c2b-451d-80c6-e173c22c592b",
   "metadata": {},
   "source": [
    "We find that at least for this data set, the relative demand for associate versus mid-senior level developers for AI is almost identical to the relative demand of the same for general developers. Notably, demand for mid-senior is slightly lower for ML-related jobs, although it remains to be seen if this is statistically significant. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f4b7ad-4233-406c-8eed-d82fecc1fca2",
   "metadata": {},
   "source": [
    "Next, within the AI subset, we wanted to see which skills were most in demand. For this we will take our list of AI related job skill keywords and construct a new dataframe with a dictionary using the keywords as keys and the frequencies as values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a404a921-8361-4626-9513-1979f2b2f59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a list comprehension and the dict method to turn tuples into key value pairs\n",
    "keyword_dict = dict([(keyword, 0) for keyword in terms_to_match])\n",
    "# Count the frequencies the terms appear in each skill set\n",
    "def increment_keywords(term_list:list, dictionary: dict): \n",
    "    for skill in term_list:\n",
    "        if skill in dictionary:\n",
    "            dictionary[skill] += 1\n",
    "    return term_list\n",
    "ai_roles['job_skills'].apply(lambda skills: increment_keywords(skills, keyword_dict))\n",
    "#Convert dict to series \n",
    "ai_skill_series = pd.Series(keyword_dict)\n",
    "\n",
    "# Here we clean up the data by de-duplicating different keyword lables and sum them together \n",
    "label_mapping = {'artificial intelligence': 'ai', 'natural language processing': 'nlp', 'large language models': 'llms', 'llm': 'llms', 'generative models' : 'genai', 'generative ai': 'genai'}\n",
    "\n",
    "# Replace the labels in the series index\n",
    "ai_skill_series.index = ai_skill_series.index.to_series().replace(label_mapping)\n",
    "\n",
    "# Aggregate the data - sum the values with the same label\n",
    "ai_skill_series = ai_skill_series.groupby(ai_skill_series.index).sum()\n",
    "\n",
    "# Display the resulting series\n",
    "print(ai_skill_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd44bbee-03ce-4ee5-a3b4-bfe8834bc2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_skill_series.sort_values(ascending=False).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e57ff8d-6ac5-4644-bc6d-7de0233e60b8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f01af664-f05d-4bf5-b90f-b919eebf4f29",
   "metadata": {},
   "source": [
    "We are also interested in the more general skill breakdown. Within the AI-related job listings, how in demand are the skills our previous term filter didn't control for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a73785b-10b2-4cca-87b4-90fbc933206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_skills(skills, label_mapping):\n",
    "    # Get a list of all job skills in the ai roles\n",
    "    skill_list_of_lists = skills.values.tolist()\n",
    "    #Merge list of lists to 1d list\n",
    "    merged_skill_lists = sum(skill_list_of_lists, [])\n",
    "    skill_series = pd.Series(merged_skill_lists)\n",
    "    # Get the unique labels for skills\n",
    "    flattened_skill_list = skill_series.tolist()\n",
    "    unqiue_skill_list = skill_series.unique().tolist()\n",
    "    # Create a dictionary to count each occurence of the skill\n",
    "    unique_dict = dict([(keyword, 0) for keyword in unique_skills_list])\n",
    "    increment_keywords(flattened_skill_list, unique_dict)\n",
    "    skill_count_series = pd.Series(unique_dict).sort_values(ascending=False)\n",
    "    # Aggregate any specified retundant labels and sum them under the same grouping\n",
    "    skill_count_series.index = skill_count_series.index.to_series().replace(label_mapping)\n",
    "    skill_count_series = skill_count_series.groupby(skill_count_series.index).sum()\n",
    "    return skill_count_series\n",
    "# all_job_skills =  count_skills(ai_roles['job_skills'], unique_dict, label_mapping)\n",
    "\n",
    "all_job_skills_series =  count_skills(ai_roles['job_skills'], label_mapping)\n",
    "# Sort and display the top 20 most in demand skills, both including and not including our AI keywords\n",
    "display(all_job_skills_series.sort_values(ascending=False).head(20).plot(kind='bar', title='Most in Demand Skills for AI Telated Jobs'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3353cf-5b9c-4210-9f95-0a6b86dee992",
   "metadata": {},
   "source": [
    "Not unexpectedly, python appears to be highly in demand for machine learning roles. Note also that among roles that contain some AI focused facet, machine learning is the most frequently occuring skill overall. \n",
    "\n",
    "Perhaps more interesting is that a fraction of job listings including machine learning do not also include python as an additional skill, as the number of counts for the python keyword is less than the counts for machine learning. This raises the question: do those roles including machine learning but excluding python have anything in common or special about them? \n",
    "\n",
    "For this query we specify a filter condition where we search for data items in the job skills column that have the keyword \"machine learning\" but not the keyword \"python\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825bbddd-3bec-482b-87cf-136c37b5987a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07b9948d-043c-417d-8d22-80f3577f7e5c",
   "metadata": {},
   "source": [
    "Another point of comparison is to measure the degree of overlap between skills for ai related roles and general software roles when controlling for the AI-specific skills. In other words, how similar are the skill demands for all software jobs when machine learning results are excluded?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62804b9-4da2-4934-b16c-686b7fda3e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, take the above results but filter out the AI related keywords by applying a data mask\n",
    "mask = all_job_skills_series.index.to_series().apply(lambda x: not any(keyword in x for keyword in terms_to_match))\n",
    "filtered_skills = all_job_skills_series[mask]\n",
    "\n",
    "#Next, apply the skills sorting logic above to the general roles dataframe \n",
    "# Get a list of all job skills in the ai roles\n",
    "all_job_skills_general = count_skills(general_roles['job_skills'], {})\n",
    "\n",
    "def render_normalized_plot(series1, series2, plot_title, column_names, xlabel, ylabel, display_count):\n",
    "    # Normalize the series\n",
    "    normalized_series1 = (series1 / series1.sum()) * 100\n",
    "    normalized_series2 = (series2 / series2.sum()) * 100\n",
    "    \n",
    "    # Create a DataFrame with the normalized data\n",
    "    df_normalized = pd.DataFrame({\n",
    "        column_names[0]: normalized_series1,\n",
    "        column_names[1]: normalized_series2\n",
    "    }).fillna(0)  # Ensure no NaN values\n",
    "    \n",
    "    # Sort the DataFrame based on the first column\n",
    "    df_normalized = df_normalized.sort_values(by=column_names[0], ascending=False).head(display_count)\n",
    "    \n",
    "    # Plot the normalized data\n",
    "    ax = df_normalized.plot(kind='bar', width=0.8, figsize=(14, 7), color=['skyblue', 'red'], alpha=0.7)\n",
    "    plt.title(plot_title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.legend(title='Dataset')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Assuming filtered_skills and all_job_skills_general are defined\n",
    "render_normalized_plot(\n",
    "    filtered_skills, \n",
    "    all_job_skills_general, \n",
    "    'Normalized Comparison of Top 20 Skills for AI and non-AI SWE jobs', \n",
    "    ['Normalized AI Job Skills', 'Normalized General Job Skills'], \n",
    "    'Skills', \n",
    "    'Percentage of Total Mentions (%)',\n",
    "    20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c2c137-bc8b-4940-91c7-8ae2d36ea1bb",
   "metadata": {},
   "source": [
    "The above comparative bar chart shows the breakdown of relative demand for desired skills for machine learning engineers compared to general software engineers as a proportion of total mentions, controlled for AI-specific keywords. Skills that have only one bar in the y axis are skills that did not appear at all in the top skills of the respective data set. \n",
    "\n",
    "What is most striking about this graph is that the most in demand skills for both data sets are comparable. For both datasets, python and  java are the most in demand skills overall, with aws, javascript and sql appearing close to the top as well with slightly different rankings. \n",
    "\n",
    "It is also curious that \"software engineering\" as a distinct skill is rated more highly for the AI roles as the 4th overall skill, whereas it is ranked 9th for the general developer roles. One possible explanation is simply that the number of skills overall for general software roles is likely much greater, simply because the data set is several times larger than the AI role subset. This would increase the odds that more skills overall are mentioned and could bias the data.\n",
    "\n",
    "Two cloud computing related keywords, \"azure\" and \"cloud computing\" appear for the AI related roles but not the general roles.\n",
    "\n",
    "Demand for python is notably elevated for the AI data set, but most skills that are shared between both data sets appear with almost the same proportional frequency. It would make sense that web technologies such as html, angular and css might be missing from the AI data set, as ML roles are unlikely to put much emphasis on browser based, frontend web development. A notable exception is that demand for react, a frontend UI framework, is comprable between datasets. Interest in data science and devops for AI roles only is also featured. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bebf53a-5868-427a-b216-fbf3ee032975",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e478afe1-e687-40d8-b146-bd1da49e705b",
   "metadata": {},
   "source": [
    "For one final point of comparision between AI-related and general SWE roles, we wanted to see if there was a meaningful difference in minimum requirements for years of experience. We would expect that Machine Learning, being a newer field, would have lower minimum requirements compared to the baseline. \n",
    "\n",
    "Because the raw data did not include a nicely isolated years of experience field, but did contain a job_summary field which follows a somewhat industry standard template,  it is possible in principle to parse out years of experience from the job description. However the caveat is that given the irregularity of the summary texts, not all information can be reliably extracted. At best we can use a regex heursitic to get some of the years of experience information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70b938e-0a58-4f8e-9939-1720f7ac2745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to do some regex matching for the most common string patterns. For \"years of experience\" as a first approximation \n",
    "# we found that the most common patterns are ranges n-m, as in 3-5 years of experience, a minimum number and a plus sign n+ years of experience, or a single number, n years of experience.  \n",
    "def match_number_patterns(text):\n",
    "    #First clear all whitespaces from the string\n",
    "    cleaned_str = text.replace(' ', '')\n",
    "    # Construct the regular expression to account for the above cases\n",
    "    pattern = r'(\\d+-\\d+|\\d+\\+|\\d+)'\n",
    "    # Find all matches using the re library\n",
    "    matches = re.findall(pattern, text)\n",
    "    if matches:\n",
    "        # Joining all matches\n",
    "        return ''.join(matches) \n",
    "        # Return None if no matches were found\n",
    "    return None \n",
    "\n",
    "\n",
    "def extract_info_from_summaries(summary: str, search_term: str, slice_length: int):\n",
    "    # Find the index of the first character of the first instance of the search term\n",
    "    search_term_index = summary.find(search_term)\n",
    "    # Check if the search term is found\n",
    "    if search_term_index != -1:\n",
    "        # Calculate start index based on slice length\n",
    "        start_index = search_term_index + slice_length if slice_length < 0 else search_term_index\n",
    "        # Adjust the end index if slice_length is negative\n",
    "        end_index = search_term_index if slice_length < 0 else search_term_index + slice_length\n",
    "        # Return the substring\n",
    "        return match_number_patterns(summary[start_index:end_index])\n",
    "    else:\n",
    "        # Return None if the search term is not found\n",
    "        return None\n",
    "\n",
    "# Apply the extract_info function to the job summaries of both dataframes \n",
    "ai_roles['years_exp'] = ai_roles.loc[:,'job_summary'].apply(lambda summary : extract_info_from_summaries(summary, 'years of experience', -4))\n",
    "general_roles['years_exp'] = general_roles.loc[:,'job_summary'].apply(lambda summary : extract_info_from_summaries(summary, 'years of', -4))\n",
    "\n",
    "# This function will fail to extract meaningful info for many entries, populating indexes of the list with None or if the re.findall condition triggers, 'nan'\n",
    "# Additional filtering is necessary to remove the nullish entries \n",
    "filtered_years_exp_ai = [entry for entry in ai_roles['years_exp'].tolist() if entry and str(entry).lower() != 'nan']\n",
    "filtered_years_exp_general = [entry for entry in general_roles['years_exp'].tolist() if entry and str(entry).lower() != 'nan']\n",
    "#Finally, we are left with string character representations of numeric information. Since we want to conduct some basic statistics on this data\n",
    "# one last round of processing is necessary to remove non-numeric symbols such as '+' signs, and to take the lower value of any ranges\n",
    "def cast_to_int(string: str):\n",
    "    # Remove '+' symbols at the end of the string\n",
    "    if string.endswith('+'):\n",
    "        return int(string[:-1])\n",
    "\n",
    "    # If the string contains a range indicated by '-', take the lower bound\n",
    "    if '-' in string:\n",
    "        lower_bound = string.split('-')[0]  # Split the string at '-' and take the first part\n",
    "        return int(lower_bound) \n",
    "\n",
    "    # If the string is a plain number, directly convert it to an integer\n",
    "    return int(string)\n",
    "\n",
    "finalized_years_ai = [cast_to_int(entry) for entry in filtered_years_exp_ai]\n",
    "finalized_years_general = [cast_to_int(entry) for entry in filtered_years_exp_general]\n",
    "\n",
    "years_ai_series = pd.Series(finalized_years_ai)\n",
    "years_general_series = pd.Series(finalized_years_general)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cae7e1-7786-4858-a747-89c02d00f2f0",
   "metadata": {},
   "source": [
    "Having now obtained our rough years of experience, some outliers required investigation. Impossible values such as 200, or less plausible values such as 20, proved to be references to the company's years of experience upon manual inspection of the csv. For example several Raytheon job listings contained the string \"we bring the strength of more than 100 years of experience and renowned engineering expertise...\" After filtering out these and other manually corrected invalid data points, the data is ready for analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2946f2c9-acd0-4b47-98f9-c9fe963db966",
   "metadata": {},
   "outputs": [],
   "source": [
    "years_ai_series = years_ai_series[years_ai_series < 16].sort_values(ascending=False)\n",
    "years_general_series = years_general_series[years_general_series < 20].sort_values(ascending=False)\n",
    "years_of_experience_df = pd.DataFrame({\n",
    "    'Minimum Years Experience for AI roles': years_ai_series,\n",
    "    'Minimum Years Experience for General Roles': years_general_series\n",
    "})\n",
    "years_of_experience_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07362e6b-465c-40d1-b21a-39ba3258674b",
   "metadata": {},
   "source": [
    "*Interpretation:* \n",
    "As predicted, the average years of experience is lower for ML roles, although not by a significant margin. Considering the imperfections of the methods employed, it could be worthwhile to see if improved extraction techniques might further refine this finding. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d996fe-807b-4a50-a3f0-c76e3b1d5a9d",
   "metadata": {},
   "source": [
    "Q2 Summary \\[INSERT SUMMARY HERE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec9a3b8-f454-4667-80df-df67cf08a27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some geography related pre-processing\n",
    "\n",
    "# Get the initials of each state\n",
    "state_abbreviations = [\n",
    "    \"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\",\n",
    "    \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\",\n",
    "    \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\",\n",
    "    \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\",\n",
    "    \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"\n",
    "    ]\n",
    "def get_location(location_str: str):\n",
    "   # Note: because the job_location field is inconsistent in the data set, we need to do a little data preparation  \n",
    "    if location_str[-2:] == 'om':\n",
    "        #handle British jobs  as the last two characters means United Kingd*om\n",
    "        return \n",
    "    elif location_str[-2:] == 'da':\n",
    "        #handle Canadian jobs \n",
    "        return \n",
    "    elif not any(location_str[-2:] == abbreviation for abbreviation in state_abbreviations):\n",
    "        # Handle the situation where the string is too heterogenous to classify within reasonable bounds\n",
    "        return\n",
    "    else :\n",
    "        #Otherwise simply return the state abbreviation \n",
    "        return location_str[-2:]\n",
    "\n",
    "linkedin_postings_df['State'] = linkedin_postings_df['job_location'].apply(lambda item: get_location(item))\n",
    "state_counts = linkedin_postings_df['State'].value_counts().reset_index()\n",
    "state_counts.columns = ['State', 'Count']\n",
    "geo_df = geo_df = state_counts.copy()\n",
    "geo_df.set_index('State').plot(kind='bar', figsize=(15, 9), width=0.9, legend=False, title='Tech Jobs by US State')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcab479-c987-4b17-8bb6-0abd224afdc7",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "California has the most job listings by a wide margin (about x2 its nearest competitor TX), as expected considering that it is the traditional tech hub for the US. The healthy showing of job listings in Texas and Florida might be attributed to the generous tax breaks and buisness friendly environment.\n",
    "\n",
    "Next, we want to see if there is any proportional difference in the distribution of AI related roles to baseline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0210956-97d1-49b3-8cbb-a86a5bb22ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply get_location function to extract states\n",
    "ai_roles['State'] = ai_roles.loc[:,'job_location'].apply(lambda item: get_location(item))\n",
    "general_roles['State'] = general_roles.loc[:,'job_location'].apply(lambda item: get_location(item))\n",
    "\n",
    "# Plot the raw counts for ML jobs separately \n",
    "ai_roles.loc[:,'State'].value_counts().plot(kind='bar', figsize=(15, 9), width=0.9, legend=False, title='AI Jobs by US State')\n",
    "\n",
    "# Count the number of jobs per state\n",
    "ai_state_counts = ai_roles.loc[:,'State'].value_counts().reset_index()\n",
    "ai_state_counts.columns = ['State', 'Count']\n",
    "general_state_counts = general_roles.loc[:,'State'].value_counts().reset_index()\n",
    "general_state_counts.columns = ['State', 'Count']\n",
    "\n",
    "# Ensure the Count columns are numeric\n",
    "ai_state_counts.loc[:, 'Count'] = pd.to_numeric(ai_state_counts['Count']).sort_values(ascending=False)\n",
    "general_state_counts.loc[:, 'Count'] = pd.to_numeric(general_state_counts['Count']).sort_values(ascending=False)\n",
    "# Merge the DataFrames to align the states\n",
    "merged_counts = pd.merge(ai_state_counts, general_state_counts, on='State', how='outer', suffixes=('_AI', '_General')).fillna(0)\n",
    "merged_counts.set_index('State', inplace=True)\n",
    "render_normalized_plot(\n",
    "    merged_counts['Count_AI'], merged_counts['Count_General'], \n",
    "    'Normalized Comparison of Job Distribution by State for AI and Non-AI Related Tech Jobs',\n",
    "    ['Normalized AI Job Counts', 'Normalized General Job Counts'],\n",
    "    'State',\n",
    "    'Percentage of Total Mentions (%)',\n",
    "    50\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054ace55-cfca-4da5-ae42-62d92fa6fcc6",
   "metadata": {},
   "source": [
    "**Interpretation** \n",
    "These findings show a different picture. The proportion of ML jobs is far greater in CA than for non-AI tech jobs. MA both has the second largest count and is disproportionately favored for ML jobs compared to baseline, followed by WA. One possible conjecture for this is that MA is a major research hub state, so one might assume demand for ML in that state would be higher than average considering its wide application for R&D purposes. The notably greater proportion of ML roles in WA could be explained by the fact that both Microsoft, which has been investing heavily in AI, and Amazon are headquartered in that state. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c3e779-2aff-4c12-9ed7-c6ae77e7ea03",
   "metadata": {},
   "source": [
    "Question Job Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3dcc07-cb01-458a-a442-2bad3bfcc572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# etc "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e56aec-4370-48c3-81ed-22ed978a51d2",
   "metadata": {},
   "source": [
    "Q3 Summary \\[INSERT SUMMARY HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813c3fef-681b-4288-a9e3-5a9cc060e407",
   "metadata": {},
   "source": [
    "Question Seniority/Job level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba54f05-1858-4ac3-890a-03d619c40df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# etc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db62c3b9-1466-4cd8-9153-082639039b35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edbae802-203f-4bda-95e0-ceaf97b8a368",
   "metadata": {},
   "source": [
    "Question 5 Industry demand "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7e4385-3e99-49d9-97d6-f3aa1f5533a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_dev",
   "language": "python",
   "name": "ai_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
