{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7209e4-3605-478b-99da-26069ad65d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required libraries\n",
    "!pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c9ded7-b4be-4175-933f-3df2b445cfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "# NOTE: We might not use all of these. I just improrted everything I can think of for now. We'll delete the ones we don't need later\n",
    "import requests\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import json\n",
    "import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681e429e-361f-401b-880d-1a9b83533c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data into the notebook\n",
    "linkedin_postings_df = pd.read_csv('./data_sets/postings.csv').dropna()\n",
    "machine_learning_jobs_df = pd.read_json('./data_sets/job_data.json', lines=True)\n",
    "\n",
    "# Normalize, clean, massage, and combine data for ease of processing\n",
    "\n",
    "# Cast all job skills to lower case strings to standardize string matching later\n",
    "linkedin_postings_df['job_skills'] = linkedin_postings_df['job_skills'].apply(lambda item: item.lower().split(', '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dad630-f2c6-4262-92c4-a63ffc8c0cdb",
   "metadata": {},
   "source": [
    "***Introduction*** \n",
    "The goal of this exploratory data analysis is to characterize and investigate the growth of machine learning as a job skill. We are interested in looking at this topic along a number angles. TBC....\n",
    "Our dataset includes 9367 job postings takend from linkedin for the 2023 calendar year. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d17b49a-4c47-4758-817c-2084eed6651d",
   "metadata": {},
   "source": [
    "QUESTION Geography "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec3de0c-bc6d-4497-9c21-6ee5549343e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Question 1 analysis and visualizations here. Insert new cells if necessary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00c0439-518c-40c7-bd8f-87660d6adb82",
   "metadata": {},
   "source": [
    "Q1 Summary \\[INSERT SUMMARY HERE] ... write a little about what the findings above seem to indicate about question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2796093-8afa-492d-a021-b5e54cb2d645",
   "metadata": {},
   "source": [
    "**Section 2: Relative Comparisons of Tech Workers with/without Machine Learning **\n",
    "Another dimension by which to look at the growth of machine learning is to compare software developers *with* ML experience to those *without* machine learning experience. Layoffs among general tech workers have been pronounced in recent months [Link](https://layoffs.fyi/) yet demand for Machine Learning engineers has reportedly increased 42% on Hired's platform [Link](https://hired.com/resources/articles/trends-software-engineer-specializations/) . This demonstrates that as a specialization, ML ought to be treated separately from other tech skills.\n",
    "\n",
    "***Basic metrics***\n",
    "As a firsts step, we compare the relative proportion of machine learning related job listings to those lacking that term. We achieve this by doing a string match through the data set using a common list of ML related terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18886b70-e0cc-4ecd-a7fd-2ac608dd22fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all job listings with an AI related keyword  listed as a skill requirement \n",
    "terms_to_match = ['machine learning', 'artificial intelligence', 'pytorch', 'langchain', 'ai', 'tensorflow', 'deep learning', 'neural network', \n",
    "               'natural language processing', 'nlp', 'computer vision', 'large language models', 'chatbot', 'ai chatbot', 'llm', 'llms', 'generative ai', 'generative models', 'genai', 'bert', 'spacy', 'nltk', 'keras', 'gpt', 'chatgpt', 'prompt development', 'prompt engineering']\n",
    "\n",
    "linkedin_postings_df['job_skills'] = linkedin_postings_df['job_skills']\n",
    "\n",
    "linkedin_postings_df['has_ai'] = linkedin_postings_df['job_skills'].apply(\n",
    "    lambda skills: any(term in skills for term in terms_to_match)\n",
    ")\n",
    "#Separate the groupings into two new dataframes\n",
    "ai_roles = linkedin_postings_df.loc[linkedin_postings_df['has_ai'] == True]\n",
    "# Job listings without AI keywords will be classified as \"general\" roles\n",
    "general_roles = linkedin_postings_df.loc[linkedin_postings_df['has_ai'] == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811d415a-539d-4be0-ba3b-40997e599697",
   "metadata": {},
   "source": [
    "Relative proportion of ML jobs to non-ML tech jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c38774-13ec-442f-824d-21caeb9ac016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw counts of ML to non-ML\n",
    "display(linkedin_postings_df['has_ai'].value_counts())\n",
    "# Proportion of ML to non-ML\n",
    "display(linkedin_postings_df['has_ai'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fac1df-30ed-4197-8a1f-11e235cede69",
   "metadata": {},
   "source": [
    "Given that x of the y job listings contain an AI related keyword, approximately z% of all listings are AI-related to some degree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bde191-1386-48d8-bc5e-f59699069c8b",
   "metadata": {},
   "source": [
    "Another dimension we want to investigate is the relative proportion of job levels, or experience requirements. Considering that AI is a newer skill set, we predict a greater proportion of entry level positions compared to generic tech roles based on skills that have been around longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9c1fec-6706-4c96-b23e-b69dc779cfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ai_roles['job level'].value_counts(normalize=True))\n",
    "print(general_roles['job level'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92137d1-0c2b-451d-80c6-e173c22c592b",
   "metadata": {},
   "source": [
    "We find that at least for this data set, the relative demand for associate versus mid-senior level developers for AI is almost identical to the relative demand of the same for general developers. Notably, demand for mid-senior is slightly lower for ML-related jobs, although it remains to be seen if this is statistically significant. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f4b7ad-4233-406c-8eed-d82fecc1fca2",
   "metadata": {},
   "source": [
    "Next, within the AI subset, we wanted to see which skills were most in demand. For this we will take our list of AI related job skill keywords and construct a new dataframe with a dictionary using the keywords as keys and the frequencies as values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a404a921-8361-4626-9513-1979f2b2f59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a list comprehension and the dict method to turn tuples into key value pairs\n",
    "keyword_dict = dict([(keyword, 0) for keyword in terms_to_match])\n",
    "# Count the frequencies the terms appear in each skill set\n",
    "def increment_keywords(term_list:list, dictionary: dict): \n",
    "    for skill in term_list:\n",
    "        if skill in dictionary:\n",
    "            dictionary[skill] += 1\n",
    "    return term_list\n",
    "ai_roles['job_skills'].apply(lambda skills: increment_keywords(skills, keyword_dict))\n",
    "#Convert dict to series \n",
    "skill_series = pd.Series(keyword_dict)\n",
    "\n",
    "# Here we de-duplicate different keyword lables and sum them together \n",
    "label_mapping = {'artificial intelligence': 'ai', 'natural language processing': 'nlp', 'large language models': 'llms', 'llm': 'llms', 'generative models' : 'genai', 'generative ai': 'genai'}\n",
    "\n",
    "# Replace the labels in the series index\n",
    "skill_series.index = skill_series.index.to_series().replace(label_mapping)\n",
    "\n",
    "# Aggregate the data - sum the values with the same label\n",
    "skill_series = skill_series.groupby(skill_series.index).sum()\n",
    "\n",
    "# Display the resulting series\n",
    "print(skill_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd44bbee-03ce-4ee5-a3b4-bfe8834bc2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_series.sort_values(ascending=False).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01af664-f05d-4bf5-b90f-b919eebf4f29",
   "metadata": {},
   "source": [
    "We are also interested in the more general skill breakdown. Among roles where AI related skills are desired how do other tech skills relate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a73785b-10b2-4cca-87b4-90fbc933206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all job skills in the ai roles\n",
    "all_job_skills =  ai_roles['job_skills'].values.tolist()\n",
    "#Merge list of lists to 1d list\n",
    "merged_skill_lists = sum(all_job_skills, [])\n",
    "skills_series = pd.Series(merged_skill_lists)\n",
    "raw_skills_list = skills_series.tolist()\n",
    "# Get the unique labels for skills\n",
    "unique_skills_list = skills_series.unique().tolist()\n",
    "# Create a dictionary to count each occurence of the skill \n",
    "unique_dict = dict([(keyword, 0) for keyword in unique_skills_list])\n",
    "increment_keywords(raw_skills_list, unique_dict)\n",
    "skill_count_series = pd.Series(unique_dict).sort_values(ascending=False)\n",
    "skill_count_series.head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d996fe-807b-4a50-a3f0-c76e3b1d5a9d",
   "metadata": {},
   "source": [
    "Q2 Summary \\[INSERT SUMMARY HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bebf53a-5868-427a-b216-fbf3ee032975",
   "metadata": {},
   "source": [
    "Geographic Distributions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec9a3b8-f454-4667-80df-df67cf08a27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some geography related pre-processing\n",
    "\n",
    "# Get the initials of each state\n",
    "state_abbreviations = [\n",
    "    \"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\",\n",
    "    \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\",\n",
    "    \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\",\n",
    "    \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\",\n",
    "    \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"\n",
    "    ]\n",
    "def get_location(location_str: str):\n",
    "   # Note: because the job_location field is inconsistent in the data set, we need to do a little data preparation  \n",
    "    if location_str[-2:] == 'om':\n",
    "        #handle British jobs  as the last two characters means United Kingd*om\n",
    "        return 'UK'\n",
    "    elif location_str[-2:] == 'da':\n",
    "        #handle Canadian jobs \n",
    "        return 'CAN'\n",
    "    elif not any(location_str[-2:] == abbreviation for abbreviation in state_abbreviations):\n",
    "        # Handle the situation where the string is too heterogenous to classify within reasonable bounds\n",
    "        return \"N/A\"\n",
    "    else :\n",
    "        #Otherwise simply return the state abbreviation \n",
    "        return location_str[-2:]\n",
    "\n",
    "linkedin_postings_df['job_state'] = linkedin_postings_df['job_location'].apply(lambda item: get_location(item))\n",
    "linkedin_postings_df['job_state'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c3e779-2aff-4c12-9ed7-c6ae77e7ea03",
   "metadata": {},
   "source": [
    "Question Job Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3dcc07-cb01-458a-a442-2bad3bfcc572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# etc "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e56aec-4370-48c3-81ed-22ed978a51d2",
   "metadata": {},
   "source": [
    "Q3 Summary \\[INSERT SUMMARY HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813c3fef-681b-4288-a9e3-5a9cc060e407",
   "metadata": {},
   "source": [
    "Question Seniority/Job level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba54f05-1858-4ac3-890a-03d619c40df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# etc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db62c3b9-1466-4cd8-9153-082639039b35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edbae802-203f-4bda-95e0-ceaf97b8a368",
   "metadata": {},
   "source": [
    "Question 5 Industry demand "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7e4385-3e99-49d9-97d6-f3aa1f5533a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_dev",
   "language": "python",
   "name": "ai_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
